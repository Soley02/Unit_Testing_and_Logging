{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorators\n",
    "from functools import wraps\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_logger(orig_func):\n",
    "    import logging\n",
    "    logging.basicConfig(filename='{}.log'.format(orig_func.__name__), level=logging.INFO)\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        #logging.info('Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
    "        \n",
    "        if(test_accuracy> 70):\n",
    "            logging.info('Die Test Accuracy ist hoch: ' + str(test_accuracy))\n",
    "        else:\n",
    "            logging.info('Die Test Accuracy ist niedrig: ' + str(test_accuracy))\n",
    "        return orig_func(*args, **kwargs)\n",
    "    \n",
    "    return wrapper\n",
    "\n",
    "def my_timer(orig_func):\n",
    "    import time\n",
    "\n",
    "    @wraps(orig_func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = orig_func(*args, **kwargs)\n",
    "        t2 = time.time() - t1\n",
    "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        logging.info('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheAlgorithm(object):\n",
    "  \n",
    "    #@my_logger\n",
    "    #@my_timer\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):  \n",
    "      self.X_train, self.y_train, self.X_test, self.y_test = X_train, y_train, X_test, y_test    \n",
    "        \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def fit(self): \n",
    "        normalizer = Normalize()\n",
    "        self.X_train, self.X_test = normalizer.normalize(self.X_train, self.X_test)   \n",
    "        train_samples = self.X_train.shape[0]\n",
    "        self.classifier = LogisticRegression(\n",
    "            C=50. / train_samples,\n",
    "            multi_class='multinomial',\n",
    "            penalty='l1',\n",
    "            solver='saga',\n",
    "            tol=0.1,\n",
    "            class_weight='balanced',\n",
    "            )\n",
    "        self.classifier.fit(self.X_train, self.y_train)\n",
    "        self.train_y_predicted = self.classifier.predict(self.X_train)\n",
    "        self.train_accuracy = np.mean(self.train_y_predicted.ravel() == self.y_train.ravel()) * 100\n",
    "        self.train_confusion_matrix = confusion_matrix(self.y_train, self.train_y_predicted)        \n",
    "        return self.train_accuracy\n",
    "    \n",
    "    @my_logger\n",
    "    @my_timer\n",
    "    def predict(self):\n",
    "        self.test_y_predicted = self.classifier.predict(self.X_test) \n",
    "        self.test_accuracy = np.mean(self.test_y_predicted.ravel() == self.y_test.ravel()) * 100 \n",
    "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_y_predicted)        \n",
    "        self.report = classification_report(self.y_test, self.test_y_predicted)\n",
    "        print(\"Classification report for classifier:\\n %s\\n\" % (self.report))\n",
    "        return self.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    X = mnist.data.astype('float64')\n",
    "    y = mnist.target\n",
    "    return (X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object): \n",
    "    def normalize(self, X_train, X_test):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        X_train = self.scaler.fit_transform(X_train)\n",
    "        X_test  = self.scaler.transform(X_test)\n",
    "        return (X_train, X_test) \n",
    "    \n",
    "    def inverse(self, X_train, X_val, X_test):\n",
    "        X_train = self.scaler.inverse_transform(X_train)\n",
    "        X_test  = self.scaler.inverse_transform(X_test)\n",
    "        return (X_train, X_test)   \n",
    "\n",
    "def split(X,y, splitRatio):\n",
    "    X_train = X[:splitRatio]\n",
    "    y_train = y[:splitRatio]\n",
    "    X_test = X[splitRatio:]\n",
    "    y_test = y[splitRatio:]\n",
    "    return (X_train, y_train, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST: (70000, 784) (70000,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-600ab9436796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m31337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheAlgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b38947d632dd>\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#logging.info('Ran with args: {}, and kwargs: {}'.format(args, kwargs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Die Test Accuracy ist hoch: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "#The solution\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "        X,y = download()\n",
    "        print ('MNIST:', X.shape, y.shape)\n",
    "  \n",
    "        splitRatio = 60000\n",
    "        X_train, y_train, X_test, y_test = split(X,y,splitRatio) \n",
    "\n",
    "        np.random.seed(31337)\n",
    "        ta = TheAlgorithm(X_train, y_train, X_test, y_test)\n",
    "        train_accuracy = ta.fit()\n",
    "        print()\n",
    "        print('Train Accuracy:', train_accuracy,'\\n') \n",
    "        print(\"Train confusion matrix:\\n%s\\n\" % ta.train_confusion_matrix)\n",
    "  \n",
    "        test_accuracy = ta.predict()\n",
    "        print()\n",
    "        print('Test Accuracy:', test_accuracy,'\\n') \n",
    "        print(\"Test confusion matrix:\\n%s\\n\" % ta.test_confusion_matrix)\n",
    "        \n",
    "        #print(ta.test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
